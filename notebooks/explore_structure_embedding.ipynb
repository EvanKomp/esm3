{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the embeddings of the discrete structure VAE produced for ESM3\n",
    "The VAE embeds local structure, runs global attention over the neighborhoods of the structure, then discretizes the outputs into tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. provided structural embeddings\n",
    "\n",
    "__This is how esm does it__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal to the ESM model api, eg. `model.generate` we call `model.encode` if the inputs are not already tensors. Here, we call the util function `tokenize_structure`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def tokenize_structure(\n",
    "    coordinates: torch.Tensor,\n",
    "    structure_encoder: StructureTokenEncoder,\n",
    "    structure_tokenizer: StructureTokenizer,\n",
    "    reference_sequence: str = \"\",\n",
    "    add_special_tokens: bool = True,\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    device = next(structure_encoder.parameters()).device\n",
    "    chain = ProteinChain.from_atom37(\n",
    "        coordinates, sequence=reference_sequence if reference_sequence else None\n",
    "    )\n",
    "\n",
    "    # Setup padding\n",
    "    if reference_sequence and len(reference_sequence) != coordinates.size(0):\n",
    "        raise ValueError(\n",
    "            f\"Reference sequence length ({len(reference_sequence)}) does not match the number of residues in the coordinates ({coordinates.size(0)})\"\n",
    "        )\n",
    "\n",
    "    left_pad = 0\n",
    "    right_pad = 0\n",
    "\n",
    "    if add_special_tokens:\n",
    "        left_pad += 1  # Add space for BOS token\n",
    "        right_pad += 1  # Add space for EOS token\n",
    "\n",
    "    coordinates, plddt, residue_index = chain.to_structure_encoder_inputs()\n",
    "    coordinates = coordinates.to(device)  # (1, L, 37, 3)\n",
    "    plddt = plddt.to(device)  # (1, L)\n",
    "    residue_index = residue_index.to(device)  # (1, L)\n",
    "    _, structure_tokens = structure_encoder.encode(\n",
    "        coordinates, residue_index=residue_index\n",
    "    )\n",
    "    coordinates = torch.squeeze(coordinates, dim=0)  # (L, 37, 3)  # type: ignore\n",
    "    plddt = torch.squeeze(plddt, dim=0)  # (L,)  # type: ignore\n",
    "    structure_tokens = torch.squeeze(structure_tokens, dim=0)  # (L,)  # type: ignore\n",
    "\n",
    "    # Add space for BOS and EOS tokens\n",
    "    if add_special_tokens:\n",
    "        coordinates = F.pad(\n",
    "            coordinates,\n",
    "            (0, 0, 0, 0, left_pad, right_pad),\n",
    "            value=torch.inf,\n",
    "        )\n",
    "        plddt = F.pad(plddt, (left_pad, right_pad), value=0)\n",
    "        structure_tokens = F.pad(\n",
    "            structure_tokens,\n",
    "            (left_pad, right_pad),\n",
    "            value=structure_tokenizer.pad_token_id,\n",
    "        )\n",
    "        structure_tokens[0] = structure_tokenizer.bos_token_id\n",
    "        structure_tokens[-1] = structure_tokenizer.eos_token_id\n",
    "    return coordinates, plddt, structure_tokens\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `StructureTokenEncoder` is a torch module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.pretrained import load_local_model\n",
    "from huggingface_hub import login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b9d3e74bd64e8a96f05602e433f0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 22 files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the encoder\n",
    "encoder = load_local_model('esm3_structure_encoder_v0', device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.utils.encoding import tokenize_structure\n",
    "from esm.utils.structure.protein_chain import ProteinChain\n",
    "import torch\n",
    "from esm.tokenization import get_model_tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = get_model_tokenizers('esm3_sm_open_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ProteinChain.from_rcsb('1ITU', \"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinChain(id='1ITU', sequence='DFFRDEAERIMRDSPVIDGHNDLPWQLLDMFNNRLQDERANLTTLAGTHTNIPKLRAGFVGGQFWSVYTPCDTQNKDAVRRTLEQMDVVHRMCRMYPETFLYVTSSAGIRQAFREGKVASLIGVEGGHSIDSSLGVLRALYQLGMRYLTLTHSCNTPWADNWLVDTGDSEPQSQGLSPFGQRVVKELNRLGVLIDLAHVSVATMKATLQLSRAPVIFSHSSAYSVCASRRNVPDDVLRLVKQTDSLVMVNFYNNYISCTNKANLSQVADHLDHIKEVAGARAVGFGGDFDGVPRVPEGLEDVSKYPDLIAELLRRNWTEAEVKGALADNLLRVFEAVEQASNLTQAPEEEPIPLDQLGGSCRTHYGYSS', chain_id='A', entity_id=1, residue_index=array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369]), insertion_code=array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', ''], dtype='<U4'), atom37_positions=array([[[-40.525,  -9.87 ,  -2.643],\n",
       "        [-39.79 ,  -9.325,  -3.825],\n",
       "        [-38.765, -10.354,  -4.294],\n",
       "        ...,\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan]],\n",
       "\n",
       "       [[-38.877, -10.768,  -5.555],\n",
       "        [-37.975, -11.767,  -6.115],\n",
       "        [-36.508, -11.389,  -6.096],\n",
       "        ...,\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan]],\n",
       "\n",
       "       [[-36.191, -10.172,  -6.525],\n",
       "        [-34.798,  -9.736,  -6.576],\n",
       "        [-34.127,  -9.485,  -5.225],\n",
       "        ...,\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 21.078,  11.292,   7.853],\n",
       "        [ 21.539,  12.047,   6.696],\n",
       "        [ 22.667,  12.976,   7.124],\n",
       "        ...,\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan]],\n",
       "\n",
       "       [[ 22.32 ,  13.849,   8.082],\n",
       "        [ 23.164,  14.906,   8.669],\n",
       "        [ 22.92 ,  16.216,   7.897],\n",
       "        ...,\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan]],\n",
       "\n",
       "       [[ 21.922,  16.985,   8.344],\n",
       "        [ 21.558,  18.249,   7.696],\n",
       "        [ 20.388,  18.97 ,   8.383],\n",
       "        ...,\n",
       "        [    nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan],\n",
       "        [ 19.55 ,  19.575,   7.675]]], dtype=float32), atom37_mask=array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False,  True]]), confidence=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = tokenize_structure(\n",
    "    coordinates=torch.tensor(example.atom37_positions),\n",
    "    structure_encoder=encoder,\n",
    "    structure_tokenizer=tokenizers.structure,\n",
    "    reference_sequence=example.sequence,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([371, 37, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first output is atom37 positions, did not change from input\n",
    "outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([371])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second output is attention mask for structure embedding - all ones since we did not mask anything. We can do so by naning anythin along axis 0\n",
    "outs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([371])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descrete output tokens\n",
    "outs[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the above function for tokenization, the discretization happens within the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dig into the decoder module to get continuous embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructureTokenEncoder(\n",
       "  (transformer): GeometricEncoderStack(\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x UnifiedTransformerBlock(\n",
       "        (geom_attn): GeometricReasoningOriginalImpl(\n",
       "          (s_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (proj): Linear(in_features=1024, out_features=1920, bias=True)\n",
       "          (out_proj): Linear(in_features=384, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ffn): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (2): SwiGLU()\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pre_vq_proj): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (codebook): EMACodebook()\n",
       "  (relative_positional_embedding): RelativePositionEmbedding(\n",
       "    (embedding): Embedding(66, 1024)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the encoder class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStructureTokenEncoder\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_model, n_heads, v_heads, n_layers, d_out, n_codes):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class StructureTokenEncoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, v_heads, n_layers, d_out, n_codes):\n",
    "        super().__init__()\n",
    "        # We only support fully-geometric structure token encoders for now...\n",
    "        # setting n_layers_geom to something that's not n_layers won't work because\n",
    "        # sequence ID isn't supported fully in this repo for plain-old transformers\n",
    "        self.transformer = GeometricEncoderStack(d_model, n_heads, v_heads, n_layers)\n",
    "        self.pre_vq_proj = nn.Linear(d_model, d_out)\n",
    "        self.codebook = EMACodebook(n_codes, d_out)\n",
    "        self.relative_positional_embedding = RelativePositionEmbedding(\n",
    "            32, d_model, init_std=0.02\n",
    "        )\n",
    "        self.knn = 16\n",
    "\n",
    "    def encode_local_structure(\n",
    "        self,\n",
    "        coords: torch.Tensor,\n",
    "        affine: Affine3D,\n",
    "        attention_mask: torch.Tensor,\n",
    "        sequence_id: torch.Tensor | None,\n",
    "        affine_mask: torch.Tensor,\n",
    "        residue_index: torch.Tensor | None = None,\n",
    "    ):\n",
    "        \"\"\"This function allows for a multi-layered encoder to encode tokens with a local receptive fields. The implementation is as follows:\n",
    "\n",
    "        1. Starting with (B, L) frames, we find the KNN in structure space. This now gives us (B, L, K) where the last dimension is the local\n",
    "        neighborhood of all (B, L) residues.\n",
    "        2. We reshape these frames to (B*L, K) so now we have a large batch of a bunch of local neighborhoods.\n",
    "        3. Pass the (B*L, K) local neighborhoods through a stack of geometric reasoning blocks, effectively getting all to all communication between\n",
    "        all frames in the local neighborhood.\n",
    "        4. This gives (B*L, K, d_model) embeddings, from which we need to get a single embedding per local neighborhood. We do this by simply\n",
    "        taking the embedding corresponding to the query node. This gives us (B*L, d_model) embeddings.\n",
    "        5. Reshape back to (B, L, d_model) embeddings\n",
    "        \"\"\"\n",
    "        assert coords.size(-1) == 3 and coords.size(-2) == 3, \"need N, CA, C\"\n",
    "        with torch.no_grad():\n",
    "            knn_edges, _ = self.find_knn_edges(\n",
    "                coords,\n",
    "                ~attention_mask,\n",
    "                coord_mask=affine_mask,\n",
    "                sequence_id=sequence_id,\n",
    "                knn=self.knn,\n",
    "            )\n",
    "            B, L, E = knn_edges.shape\n",
    "\n",
    "            affine_tensor = affine.tensor  # for easier manipulation\n",
    "            T_D = affine_tensor.size(-1)\n",
    "            knn_affine_tensor = node_gather(affine_tensor, knn_edges)\n",
    "            knn_affine_tensor = knn_affine_tensor.view(-1, E, T_D).contiguous()\n",
    "            affine = Affine3D.from_tensor(knn_affine_tensor)\n",
    "            knn_sequence_id = (\n",
    "                node_gather(sequence_id.unsqueeze(-1), knn_edges).view(-1, E)\n",
    "                if sequence_id is not None\n",
    "                else torch.zeros(L, E, dtype=torch.int64, device=coords.device)\n",
    "            )\n",
    "            knn_affine_mask = node_gather(affine_mask.unsqueeze(-1), knn_edges).view(\n",
    "                -1, E\n",
    "            )\n",
    "            knn_chain_id = torch.zeros(L, E, dtype=torch.int64, device=coords.device)\n",
    "\n",
    "            if residue_index is None:\n",
    "                res_idxs = knn_edges.view(-1, E)\n",
    "            else:\n",
    "                res_idxs = node_gather(residue_index.unsqueeze(-1), knn_edges).view(\n",
    "                    -1, E\n",
    "                )\n",
    "\n",
    "        z = self.relative_positional_embedding(res_idxs[:, 0], res_idxs)\n",
    "\n",
    "        z, _ = self.transformer.forward(\n",
    "            x=z,\n",
    "            sequence_id=knn_sequence_id,\n",
    "            affine=affine,\n",
    "            affine_mask=knn_affine_mask,\n",
    "            chain_id=knn_chain_id,\n",
    "        )\n",
    "\n",
    "        # Unflatten the output and take the query node embedding, which will always be the first one because\n",
    "        # a node has distance 0 with itself and the KNN are sorted.\n",
    "        z = z.view(B, L, E, -1)\n",
    "        z = z[:, :, 0, :]\n",
    "\n",
    "        return z\n",
    "\n",
    "    @staticmethod\n",
    "    def find_knn_edges(\n",
    "        coords,\n",
    "        padding_mask,\n",
    "        coord_mask,\n",
    "        sequence_id: torch.Tensor | None = None,\n",
    "        knn: int | None = None,\n",
    "    ) -> tuple:\n",
    "        assert knn is not None, \"Must specify a non-null knn to find_knn_edges\"\n",
    "        # Coords are N, CA, C\n",
    "        coords = coords.clone()\n",
    "        coords[~coord_mask] = 0\n",
    "\n",
    "        if sequence_id is None:\n",
    "            sequence_id = torch.zeros(\n",
    "                (coords.shape[0], coords.shape[1]), device=coords.device\n",
    "            ).long()\n",
    "\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n",
    "            ca = coords[..., 1, :]\n",
    "            edges, edge_mask = knn_graph(\n",
    "                ca,\n",
    "                coord_mask,\n",
    "                padding_mask,\n",
    "                sequence_id,\n",
    "                no_knn=knn,\n",
    "            )\n",
    "\n",
    "        return edges, edge_mask\n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        coords: torch.Tensor,\n",
    "        attention_mask: torch.Tensor | None = None,\n",
    "        sequence_id: torch.Tensor | None = None,\n",
    "        residue_index: torch.Tensor | None = None,\n",
    "    ):\n",
    "        coords = coords[..., :3, :]\n",
    "        affine, affine_mask = build_affine3d_from_coordinates(coords=coords)\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(affine_mask, dtype=torch.bool)\n",
    "        attention_mask = attention_mask.bool()\n",
    "\n",
    "        if sequence_id is None:\n",
    "            sequence_id = torch.zeros_like(affine_mask, dtype=torch.int64)\n",
    "\n",
    "        z = self.encode_local_structure(\n",
    "            coords=coords,\n",
    "            affine=affine,\n",
    "            attention_mask=attention_mask,\n",
    "            sequence_id=sequence_id,\n",
    "            affine_mask=affine_mask,\n",
    "            residue_index=residue_index,\n",
    "        )\n",
    "\n",
    "        z = z.masked_fill(~affine_mask.unsqueeze(2), 0)\n",
    "        z = self.pre_vq_proj(z)\n",
    "\n",
    "        z_q, min_encoding_indices, _ = self.codebook(z)\n",
    "\n",
    "        return z_q, min_encoding_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is Zq the latent space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pad = 0\n",
    "right_pad = 0\n",
    "\n",
    "coordinates, plddt, residue_index = example.to_structure_encoder_inputs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, structure_tokens = encoder.encode(\n",
    "    coordinates, residue_index=residue_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5313, -2.3629, -0.6525,  0.3052, -0.4117,  2.9609,  0.6918,  2.1311,\n",
       "          1.5440,  0.6354, -1.1304,  1.1496, -0.1755,  1.9234, -2.5304, -2.9934,\n",
       "         -0.9476, -1.0383, -0.1722, -1.8722,  1.7672, -0.3774,  1.9237,  1.4243,\n",
       "         -2.0182,  2.0026, -1.1837,  0.2101, -0.8612,  0.2164,  0.8020, -0.1875,\n",
       "          0.3853, -0.6748, -0.3127,  2.9619, -0.6505,  0.3225, -0.9738, -0.8902,\n",
       "         -0.4902,  0.5850, -0.5019, -0.5598, -0.2611,  0.5285, -0.5970, -0.3727,\n",
       "          1.9450, -1.2231, -0.1247,  2.5219, -1.6484,  1.6937,  0.6202,  1.1796,\n",
       "          1.6026,  1.2698, -1.7287, -1.0446,  0.3377, -0.4107,  0.0990,  1.4283,\n",
       "         -0.5145,  0.6338, -0.2815, -0.0670,  0.8958,  0.2626, -1.8318, -1.7010,\n",
       "         -1.2507,  2.0013, -2.4350, -1.3212, -0.6036,  0.7297, -0.8470,  0.1455,\n",
       "          1.3283,  0.9365, -0.3025,  0.5832,  0.7132,  1.0818, -0.2943,  1.9198,\n",
       "          1.9231,  0.4123,  0.7660, -0.4020,  2.0509, -1.4754,  0.6602,  1.6624,\n",
       "         -0.7840,  0.6760,  2.5660,  0.7376,  0.0131, -0.2392, -0.9468, -1.4652,\n",
       "          1.0331, -0.8039,  3.2232, -1.6770,  1.3411,  0.6426,  2.1112, -0.5960,\n",
       "          0.1406,  2.0154,  0.7548, -1.2179,  0.0355, -0.6663, -0.3077, -1.6614,\n",
       "          0.3827, -0.1968, -1.1172, -0.8176,  0.2385, -0.7399, -0.2724,  1.0589]],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
